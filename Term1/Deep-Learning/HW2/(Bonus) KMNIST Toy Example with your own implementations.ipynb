{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMNIST Example with your own implementation (BONUS)\n",
    "\n",
    "Now, in this part, you will work with Kuzushiji-MNIST data (https://github.com/rois-codh/kmnist) for character classification. \n",
    "The images contain one of the 10 characters in Kuzusjihi(cursive Japanese) Alphabet.\n",
    "Use an appropriate loss function.\n",
    "\n",
    "You should build a ConvNet architecture including all layers such as Conv2d, Maxpool, Dropout, and BatchNorm. You are free to design the layers as you like.\n",
    "\n",
    "IMPORTANT: You are NOT allowed to use sklearn or any other implementations for the learning part . You are ALLOWED ONLY TO USE your own implementation from the above steps.\n",
    "\n",
    "\"KMNIST Dataset\" (created by CODH), adapted from \"Kuzushiji Dataset\" (created by NIJL and others), doi:10.20676/00000341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blg561.layer import layers_with_weights\n",
    "from blg561.layer import layer\n",
    "from blg561.layer.optimizers import SGDWithMomentum, VanillaSDGOptimizer\n",
    "from blg561.layer.model import Model\n",
    "from blg561.checks import grad_check,rel_error\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your own dataloader\n",
    "kmnist_train_imgs_path = \"kmnist/kmnist-train-imgs.npz\"\n",
    "kmnist_train_labels_path = \"kmnist/kmnist-train-labels.npz\"\n",
    "kmnist_test_imgs_path = \"kmnist/kmnist-test-imgs.npz\"\n",
    "kmnist_test_labels_path = \"kmnist/kmnist-test-labels.npz\"\n",
    "\n",
    "def create_permutation(x, y):\n",
    "    perm = np.random.permutation(len(x))\n",
    "    return x[perm], y[perm]\n",
    "\n",
    "def load_kmnist():\n",
    "    train = np.load(kmnist_train_imgs_path)\n",
    "    train_imgs = train.f.arr_0\n",
    "    train_labels = np.load(kmnist_train_labels_path)\n",
    "    train_labels = train_labels.f.arr_0\n",
    "    test = np.load(kmnist_test_imgs_path)\n",
    "    test_imgs = test.f.arr_0\n",
    "    test_labels = np.load(kmnist_test_labels_path)\n",
    "    test_labels = test_labels.f.arr_0\n",
    "    train_imgs, train_labels = create_permutation(train_imgs,train_labels)\n",
    "    train_imgs = np.expand_dims(train_imgs, axis=1)\n",
    "    train_labels = np.expand_dims(train_labels, axis=1)\n",
    "    test_imgs = np.expand_dims(test_imgs, axis=1)\n",
    "    test_labels = np.expand_dims(test_labels, axis=1)\n",
    "    \n",
    "    return train_imgs,train_labels,test_imgs,test_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model\n",
    "\n",
    "In below, we provide an example model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "layers = [\n",
    "          layers_with_weights.Conv2d(in_size=1, out_size=3, kernel_size=5, stride=1, padding=1),\n",
    "          layer.ReLU(), \n",
    "          layers_with_weights.Conv2d(in_size=3, out_size=25, kernel_size=5, stride=2, padding=1),\n",
    "          layer.ReLU(), \n",
    "          layers_with_weights.Conv2d(in_size=25, out_size=50, kernel_size=5, stride=2, padding=1),\n",
    "          layer.ReLU(), \n",
    "          layers_with_weights.Conv2d(in_size=50, out_size=50, kernel_size=5, stride=2, padding=1),\n",
    "          layer.Flatten(), \n",
    "          layers_with_weights.AffineLayer(200, 64), \n",
    "          layer.ReLU(),\n",
    "          layers_with_weights.AffineLayer(64,10),\n",
    "          layer.Softmax()\n",
    "        ]\n",
    "model(layers) # Load layers to model object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train your model with the data and show the results as Loss Curves and Accuracy for Test in a Confusion Matrix (You can use scikit-learn's confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: nan, Accuracy: 0.105\n",
      "Epoch: 0, Test Loss: nan, Test Accuracy: 0.105\n",
      "Epoch: 1, Loss: nan, Accuracy: 0.105\n",
      "Epoch: 2, Loss: nan, Accuracy: 0.105\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-a00999e7767b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: {}, Loss: {}, Accuracy: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Deep Learning/HW2/blg561/layer/model.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# print(ix)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayerWithWeights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mdprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mdprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Deep Learning/HW2/blg561/layer/layers_with_weights.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dprev)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mh_out\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_H\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mw_out\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_W\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                         \u001b[0mdw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpadded_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_out\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mh_out\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mFH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_out\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mw_out\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mFW\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdprev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                         \u001b[0mdx_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_out\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mh_out\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mFH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_out\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mw_out\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mFW\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdprev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_accs = []\n",
    "test_accs = []\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Options\n",
    "shuffle_on_each_epoch = True\n",
    "regularization_strength = 0\n",
    "n_epochs = 100\n",
    "print_every = 1\n",
    "test_every = 100\n",
    "train_imgs,train_labels,test_imgs,test_labels = load_kmnist()\n",
    "\n",
    "optimizer = SGDWithMomentum(model,lr=1e-1, regularization_str=regularization_strength)\n",
    "#try with vanilla optimizer\n",
    "#optimizer = layer.VanillaSDGOptimizer(model,lr=1e-1, regularization_str=regularization_strength)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    softmax_out = model.forward(train_imgs[:1000])\n",
    "    \n",
    "    predictions = np.argmax(softmax_out, axis=1)\n",
    "    train_acc = np.mean(predictions == train_labels[:1000])\n",
    "    loss = layer.loss(softmax_out, train_labels[:1000])\n",
    "    \n",
    "    train_accs.append(train_acc)\n",
    "    train_losses.append(loss)\n",
    "    if epoch % print_every == 0:\n",
    "        print(\"Epoch: {}, Loss: {}, Accuracy: {}\".format(epoch, loss, train_acc))\n",
    "    \n",
    "    model.backward(train_labels[:1000])\n",
    "    optimizer.optimize()\n",
    "    \n",
    "    if epoch % test_every == 0:\n",
    "        softmax_out = model.forward(test_imgs[:1000])\n",
    "        predictions = np.argmax(softmax_out, axis=1)\n",
    "        loss = layer.loss(softmax_out, test_labels[:1000])\n",
    "        test_acc = np.mean(predictions == test_labels[:1000])\n",
    "        test_losses.append([loss for _ in range(test_every)])\n",
    "        test_accs.append([test_acc for _ in range(test_every)])\n",
    "        print(\"Epoch: {}, Test Loss: {}, Test Accuracy: {}\".format(epoch, loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
